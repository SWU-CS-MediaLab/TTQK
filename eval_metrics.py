from __future__ import print_function, absolute_import
import numpy as np
import torch
import time
import os
from torch.autograd import Variable

def eval_sysu(distmat, q_pids, g_pids, q_camids, g_camids, max_rank = 20):
    """Evaluation with sysu metric
    Key: for each query identity, its gallery images from the same camera view are discarded. "Following the original setting in ite dataset"
    """
    num_q, num_g = distmat.shape
    if num_g < max_rank:
        max_rank = num_g
        print("Note: number of gallery samples is quite small, got {}".format(num_g))
    indices = np.argsort(distmat, axis=1)
    pred_label = g_pids[indices]
    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)
    
    # compute cmc curve for each query
    new_all_cmc = []
    all_cmc = []
    all_AP = []
    all_INP = []
    num_valid_q = 0. # number of valid query
    for q_idx in range(num_q):
        # get query pid and camid
        q_pid = q_pids[q_idx]
        q_camid = q_camids[q_idx]

        # remove gallery samples that have the same pid and camid with query
        order = indices[q_idx]
        remove = (q_camid == 3) & (g_camids[order] == 2)
        keep = np.invert(remove)
        
        # compute cmc curve
        # the cmc calculation is different from standard protocol
        # we follow the protocol of the author's released code
        new_cmc = pred_label[q_idx][keep]
        new_index = np.unique(new_cmc, return_index=True)[1]
        new_cmc = [new_cmc[index] for index in sorted(new_index)]
        
        new_match = (new_cmc == q_pid).astype(np.int32)
        new_cmc = new_match.cumsum()
        new_all_cmc.append(new_cmc[:max_rank])
        
        orig_cmc = matches[q_idx][keep] # binary vector, positions with value 1 are correct matches
        if not np.any(orig_cmc):
            # this condition is true when query identity does not appear in gallery
            continue

        cmc = orig_cmc.cumsum()

        # compute mINP
        # refernece Deep Learning for Person Re-identification: A Survey and Outlook
        pos_idx = np.where(orig_cmc == 1)
        pos_max_idx = np.max(pos_idx)
        inp = cmc[pos_max_idx]/ (pos_max_idx + 1.0)
        all_INP.append(inp)

        cmc[cmc > 1] = 1

        all_cmc.append(cmc[:max_rank])
        num_valid_q += 1.

        # compute average precision
        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision
        num_rel = orig_cmc.sum()
        tmp_cmc = orig_cmc.cumsum()
        tmp_cmc = [x / (i+1.) for i, x in enumerate(tmp_cmc)]
        tmp_cmc = np.asarray(tmp_cmc) * orig_cmc
        AP = tmp_cmc.sum() / num_rel
        all_AP.append(AP)

    assert num_valid_q > 0, "Error: all query identities do not appear in gallery"
    
    all_cmc = np.asarray(all_cmc).astype(np.float32)
    all_cmc = all_cmc.sum(0) / num_valid_q   # standard CMC
    
    new_all_cmc = np.asarray(new_all_cmc).astype(np.float32)
    new_all_cmc = new_all_cmc.sum(0) / num_valid_q
    mAP = np.mean(all_AP)
    mINP = np.mean(all_INP)
    return new_all_cmc, mAP, mINP
    
def eval_regdb(distmat, q_pids, g_pids, max_rank = 20):
    num_q, num_g = distmat.shape
    if num_g < max_rank:
        max_rank = num_g
        print("Note: number of gallery samples is quite small, got {}".format(num_g))
    indices = np.argsort(distmat, axis=1)
    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)

    # compute cmc curve for each query
    all_cmc = []
    all_AP = []
    all_INP = []
    num_valid_q = 0. # number of valid query
    
    # only two cameras
    q_camids = np.ones(num_q).astype(np.int32)
    g_camids = 2* np.ones(num_g).astype(np.int32)
    
    for q_idx in range(num_q):
        # get query pid and camid
        q_pid = q_pids[q_idx]
        q_camid = q_camids[q_idx]

        # remove gallery samples that have the same pid and camid with query
        order = indices[q_idx]
        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)
        keep = np.invert(remove)

        # compute cmc curve
        raw_cmc = matches[q_idx][keep] # binary vector, positions with value 1 are correct matches
        if not np.any(raw_cmc):
            # this condition is true when query identity does not appear in gallery
            continue

        cmc = raw_cmc.cumsum()

        # compute mINP
        # refernece Deep Learning for Person Re-identification: A Survey and Outlook
        pos_idx = np.where(raw_cmc == 1)
        pos_max_idx = np.max(pos_idx)
        inp = cmc[pos_max_idx]/ (pos_max_idx + 1.0)
        all_INP.append(inp)

        cmc[cmc > 1] = 1

        all_cmc.append(cmc[:max_rank])
        num_valid_q += 1.

        # compute average precision
        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision
        num_rel = raw_cmc.sum()
        tmp_cmc = raw_cmc.cumsum()
        tmp_cmc = [x / (i+1.) for i, x in enumerate(tmp_cmc)]
        tmp_cmc = np.asarray(tmp_cmc) * raw_cmc
        AP = tmp_cmc.sum() / num_rel
        all_AP.append(AP)

    assert num_valid_q > 0, "Error: all query identities do not appear in gallery"

    all_cmc = np.asarray(all_cmc).astype(np.float32)
    all_cmc = all_cmc.sum(0) / num_valid_q
    mAP = np.mean(all_AP)
    mINP = np.mean(all_INP)
    return all_cmc, mAP, mINP


def eval_llcm(distmat, q_pids, g_pids, q_camids, g_camids, max_rank=20):
    """Evaluation with sysu metric
    Key: for each query identity, its gallery images from the same camera view are discarded. "Following the original setting in ite dataset"
    """
    num_q, num_g = distmat.shape
    if num_g < max_rank:
        max_rank = num_g
        print("Note: number of gallery samples is quite small, got {}".format(num_g))
    indices = np.argsort(distmat, axis=1)
    pred_label = g_pids[indices]
    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)

    # compute cmc curve for each query
    new_all_cmc = []
    all_cmc = []
    all_AP = []
    all_INP = []
    num_valid_q = 0.  # number of valid query
    for q_idx in range(num_q):
        # get query pid and camid
        q_pid = q_pids[q_idx]
        q_camid = q_camids[q_idx]

        # remove gallery samples that have the same pid and camid with query

        order = indices[q_idx]
        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)
        keep = np.invert(remove)

        # compute cmc curve
        # the cmc calculation is different from standard protocol
        # we follow the protocol of the author's released code
        new_cmc = pred_label[q_idx][keep]
        new_index = np.unique(new_cmc, return_index=True)[1]

        new_cmc = [new_cmc[index] for index in sorted(new_index)]

        new_match = (new_cmc == q_pid).astype(np.int32)
        new_cmc = new_match.cumsum()
        new_all_cmc.append(new_cmc[:max_rank])

        orig_cmc = matches[q_idx][keep]  # binary vector, positions with value 1 are correct matches
        if not np.any(orig_cmc):
            # this condition is true when query identity does not appear in gallery
            continue

        cmc = orig_cmc.cumsum()

        # compute mINP
        # refernece Deep Learning for Person Re-identification: A Survey and Outlook
        pos_idx = np.where(orig_cmc == 1)
        pos_max_idx = np.max(pos_idx)
        inp = cmc[pos_max_idx] / (pos_max_idx + 1.0)
        all_INP.append(inp)

        cmc[cmc > 1] = 1

        all_cmc.append(cmc[:max_rank])
        num_valid_q += 1.

        # compute average precision
        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision
        num_rel = orig_cmc.sum()
        tmp_cmc = orig_cmc.cumsum()
        tmp_cmc = [x / (i + 1.) for i, x in enumerate(tmp_cmc)]
        tmp_cmc = np.asarray(tmp_cmc) * orig_cmc
        AP = tmp_cmc.sum() / num_rel
        all_AP.append(AP)

    assert num_valid_q > 0, "Error: all query identities do not appear in gallery"

    all_cmc = np.asarray(all_cmc).astype(np.float32)
    all_cmc = all_cmc.sum(0) / num_valid_q  # standard CMC

    new_all_cmc = np.asarray(new_all_cmc).astype(np.float32)
    new_all_cmc = new_all_cmc.sum(0) / num_valid_q
    mAP = np.mean(all_AP)
    mINP = np.mean(all_INP)
    return new_all_cmc, mAP, mINP

def eval_vcm(distmat, q_pids, g_pids, q_camids, g_camids, max_rank=20):
    # print("it is evaluate ing now ")
    num_q, num_g = distmat.shape
    if num_g < max_rank:
        max_rank = num_g
        print("Note: number of gallery samples is quite small, got {}".format(num_g))
    indices = np.argsort(distmat, axis=1)
    matches = (g_pids[indices] == q_pids[:, np.newaxis]).astype(np.int32)

    # compute cmc curve for each query
    all_cmc = []
    all_AP = []
    num_valid_q = 0.
    for q_idx in range(num_q):
        # get query pid and camid
        q_pid = q_pids[q_idx]
        q_camid = q_camids[q_idx]

        # remove gallery samples that have the same pid and camid with query
        order = indices[q_idx]
        remove = (g_pids[order] == q_pid) & (g_camids[order] == q_camid)
        keep = np.invert(remove)

        # compute cmc curve
        orig_cmc = matches[q_idx][keep] # binary vector, positions with value 1 are correct matches
        if not np.any(orig_cmc):
            # this condition is true when query identity does not appear in gallery
            continue

        cmc = orig_cmc.cumsum()
        cmc[cmc > 1] = 1

        all_cmc.append(cmc[:max_rank])
        num_valid_q += 1.

        # compute average precision
        # reference: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision
        num_rel = orig_cmc.sum()
        tmp_cmc = orig_cmc.cumsum()
        tmp_cmc = [x / (i+1.) for i, x in enumerate(tmp_cmc)]
        tmp_cmc = np.asarray(tmp_cmc) * orig_cmc
        AP = tmp_cmc.sum() / num_rel
        all_AP.append(AP)

    assert num_valid_q > 0, "Error: all query identities do not appear in gallery"

    all_cmc = np.asarray(all_cmc).astype(np.float32)
    all_cmc = all_cmc.sum(0) / num_valid_q
    mAP = np.mean(all_AP)

    return all_cmc, mAP

def eval_func(net, dataset, test_loader,feat_dim,training_phase,epoch):
    gall_loader,query_loader = test_loader
    if dataset == "RegDB":
        test_mode = [2,1] # visible to thermal
    elif dataset == "SYSU-MM01":
        test_mode = [1,2] #thermal to visible
    elif dataset == "LLCM":
        test_mode =[1,2] # thermal to visible
    elif dataset == "VCM":
        test_mode = [1,2]#thermal to visible
    # switch to evaluation mode
    net.eval()
    print('Extracting Gallery Feature...')
    start = time.time()
    ptr = 0
    gall_label = gall_loader.dataset.test_label
    ngall = len(gall_label)
    gall_feat = np.zeros((ngall, feat_dim))
    idx = np.zeros(ngall)
    sim = np.zeros((ngall, training_phase))
    with torch.no_grad():
        for batch_idx, (input, label) in enumerate(gall_loader):
            batch_num = input.size(0)
            if len(input.size()) == 5:
                print(input.size())
                input = input.squeeze(1)
            input = Variable(input.cuda())
            out = net(input, input, test_mode[0],training_phase)
            feat = out["test"]
            gall_feat[ptr:ptr + batch_num, :] = feat.detach().cpu().numpy()
            idx[ptr:ptr + batch_num] = out["idx"].detach().cpu().numpy()
            sim[ptr:ptr + batch_num, :] = out["sim"].detach().cpu().numpy()
            ptr = ptr + batch_num
        log(dataset, training_phase, epoch,idx,sim,"gallery")
    print('Extracting Time:\t {:.3f}'.format(time.time() - start))

    # switch to evaluation
    net.eval()
    print('Extracting Query Feature...')
    start = time.time()
    ptr = 0
    query_label = query_loader.dataset.test_label
    nquery = len(query_label)
    query_feat = np.zeros((nquery, feat_dim))
    idx = np.zeros(nquery)
    sim = np.zeros((nquery, training_phase))
    with torch.no_grad():
        for batch_idx, (input, label) in enumerate(query_loader):
            batch_num = input.size(0)
            if len(input.size()) == 5:
                print(input.size())
                input = input.squeeze(1)
            input = Variable(input.cuda())
            out = net(input, input, test_mode[1],training_phase)
            feat = out["test"]
            query_feat[ptr:ptr + batch_num, :] = feat.detach().cpu().numpy()
            idx[ptr:ptr + batch_num] = out["idx"].detach().cpu().numpy()
            sim[ptr:ptr + batch_num, :] = out["sim"].detach().cpu().numpy()
            ptr = ptr + batch_num
        log(dataset, training_phase, epoch,idx,sim, "query")
    print('Extracting Time:\t {:.3f}'.format(time.time() - start))

    start = time.time()
    # compute the similarity
    distmat = np.matmul(query_feat, np.transpose(gall_feat))

    # evaluation
    if dataset == 'RegDB':
        cmc, mAP,_ = eval_regdb(-distmat,query_label,gall_label)
    elif dataset == 'SYSU-MM01':
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP,_ = eval_sysu(-distmat, query_label, gall_label, query_cam, gall_cam)
    elif dataset == "LLCM":
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP,_ = eval_llcm(-distmat, query_label, gall_label, query_cam, gall_cam)
    elif dataset == "VCM":
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP = eval_vcm(-distmat, query_label, gall_label, query_cam, gall_cam)
    print('Evaluation Time:\t {:.3f}'.format(time.time() - start))
    return cmc,mAP

def log(dataset,training_phase,epoch,idx,sim,mode):
    suffix = "2024.1.23_加上了neutral_loss"
    log_dir = f'./evaluate_log/{suffix}/'
    if not os.path.isdir(log_dir):
        os.mkdir(log_dir)
    log_path = log_dir + f"{training_phase}.txt"
    with open(log_path, 'a') as f:
        # idx = idx.cpu().numpy()
        idx = idx.tolist()
        f.write(f"epoch {epoch} datasets {dataset} {mode}:\r\n")
        strNums = [str(x_i) for x_i in idx]
        str1 = ",".join(strNums)
        f.write(str1)
        f.write('\r\n')
    f.close()

    log_dir = f"./inner_states/{suffix}/"
    if not os.path.isdir(log_dir):
        os.mkdir(log_dir)
    log_path = log_dir + f"{training_phase}.txt"
    with open(log_path, 'a') as f:
        mean_sim = sim.mean(axis=0)
        mean_sim = mean_sim.tolist()
        f.write(f"epoch {epoch} datasets:{dataset} {mode}:\r\n")
        strNums = [str(x_i) for x_i in mean_sim]
        str1 = ",".join(strNums)
        f.write(str1)
        f.write('\r\n')
    f.close()

def eval_func2(net, dataset, test_loader,feat_dim,training_phase,epoch = 1):
    gall_loader,query_loader = test_loader
    if dataset == "RegDB":
        test_mode = [2,1] # visible to thermal
    elif dataset == "SYSU-MM01":
        test_mode = [1,2] #thermal to visible
    elif dataset == "LLCM":
        test_mode =[1,2] # thermal to visible
    elif dataset == "VCM":
        test_mode = [1,2]#thermal to visible
    # switch to evaluation mode
    net.eval()
    print('Extracting Gallery Feature...')
    start = time.time()
    ptr = 0
    gall_label = gall_loader.dataset.test_label
    ngall = len(gall_label)
    gall_feat = np.zeros((ngall, feat_dim))
    with torch.no_grad():
        for batch_idx, (input, label) in enumerate(gall_loader):
            batch_num = input.size(0)
            if len(input.size()) == 5:
                print(input.size())
                input = input.squeeze(1)
            input = Variable(input.cuda())
            feat = net(input, input, test_mode[0],training_phase = training_phase)["test"]
            gall_feat[ptr:ptr + batch_num, :] = feat.detach().cpu().numpy()
            ptr = ptr + batch_num
    print('Extracting Time:\t {:.3f}'.format(time.time() - start))

    # switch to evaluation
    net.eval()
    print('Extracting Query Feature...')
    start = time.time()
    ptr = 0
    query_label = query_loader.dataset.test_label
    nquery = len(query_label)
    query_feat = np.zeros((nquery, feat_dim))
    with torch.no_grad():
        for batch_idx, (input, label) in enumerate(query_loader):
            batch_num = input.size(0)
            if len(input.size()) == 5:
                print(input.size())
                input = input.squeeze(1)
            input = Variable(input.cuda())
            feat = net(input, input, test_mode[1],training_phase =training_phase)["test"]
            query_feat[ptr:ptr + batch_num, :] = feat.detach().cpu().numpy()
            ptr = ptr + batch_num
    print('Extracting Time:\t {:.3f}'.format(time.time() - start))

    start = time.time()
    # compute the similarity
    distmat = np.matmul(query_feat, np.transpose(gall_feat))

    # evaluation
    if dataset == 'RegDB':
        cmc, mAP,_ = eval_regdb(-distmat,query_label,gall_label)
    elif dataset == 'SYSU-MM01':
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP,_ = eval_sysu(-distmat, query_label, gall_label, query_cam, gall_cam)
    elif dataset == "LLCM":
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP,_ = eval_llcm(-distmat, query_label, gall_label, query_cam, gall_cam)
    elif dataset == "VCM":
        query_cam = query_loader.dataset.test_cam
        gall_cam = gall_loader.dataset.test_cam
        cmc, mAP = eval_vcm(-distmat, query_label, gall_label, query_cam, gall_cam)
    print('Evaluation Time:\t {:.3f}'.format(time.time() - start))
    return cmc,mAP
